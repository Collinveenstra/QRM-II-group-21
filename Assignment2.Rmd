---
title: "QRM II Graded Assignment (2), Period 1 2025"
author: "Group 21 - Carlijn Calori, Julia Koeleman, Marit Springer & Collin Veenstra"
date: "`r format(Sys.Date(), '%d-%m-%Y')`"
output:
  word_document: default
  pdf_document:
    number_sections: true
  html_document:
    df_print: paged
subtitle: Material by Sjoerd van Alten and Klervie Toczé
header-includes:
- "\\setcounter{section}{-1}"
- |
  \usepackage{fvextra}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{
    showspaces = false,
    showtabs = false,
    breaklines,
    commandchars=\\\{\}
format:
  html:
    code-overflow: wrap
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This assignment is to be completed in groups of 3-4. Further, all students in your group need to be assigned to the same R tutorial group (Friday's tutorial). You can sign yourself up for a group on Canvas. Please do so \textbf{before the start of your first R tutorial on Friday September 5th.} You can use the Discussion Board in Canvas if you do not have a group yet or if your group is incomplete.

The assignment has 5 parts, and each part corresponds to the course material of that week (with the exclusion of week 6, for which there is no R programming material). 

You are supposed to hand in these assignments on Canvas at the following dates:

  - **Deadline 1** *Thursday September 25th, at 23:59pm*: you are supposed to hand in weeks 1, 2, and 3 of this assignment.   This will determine 18\% of your overall course grade
  - **Deadline 2** *Thursday October 9th, at 23:59pm*: you are supposed to hand in weeks 4, and 5 of this assignment. This will determine 12\% of your overall course grade 

The R tutorials (each Friday) will consist of two halves. During the first half, you will discuss the tutorial exercises. These can be downloaded separately from Canvas. During the second half, you can work on this graded assignment within your own group. The purpose is that you find out how to work with R for doing statistical analyses by yourself. The tutorial exercises are meant to teach you basic commands to get you started, but to answer the problem sets in this assignment, you might need to research your own solutions, and use functions and commands not described in the tutorial exercises. Learning how to solve your own research problems is integral part of learning R. When you and your group get stuck on how to approach an exercise, the hierarchy in finding your way is as follows:

-	use the concepts from the tutorial exercises;
- use the cheat sheets available on Canvas;
-	use Google, YouTube, StackOverflow, or another website;
- ask the teacher.

The use of generative AI is \textbf{not} permitted and may result in a grade of 0. See the AI protocol in the course manual for details.

To answer the assignment, you can simply fill out this R markdown document. There are designated places which you can fill with R code. There are also designated spaces for you to answer each question. Often, the structure of an answer will be as follows. First, you type the R code in the designated box. This will show how you analyzed the data to get the answer to the question. Below the box for the R code, you will then summarize your answer to the question, i.e. what are the conclusions that you draw from the data analysis? 

When handing in, you are supposed to submit this .Rmd file, and a knitted version of this document. You can knit this document to pdf, word, or html. Knitting to pdf requires you to have a .tex distribution installed on your computer. Knitting to Word requires you to have Word installed. 

The exercises are designed such that you should be able to finish the majority of them during the tutorial each week. If you are not able to finish them fully during that time, you are expected to work on it in your own time using the computers on campus or your own device. It is best to meet as a group in-person when working together. If you want to work remotely, github is a good platform to guarantee smooth collaboration. Alternatively, you can email this .Rmd file back and forth to one another as a group, but this is not recommended as it is more cumbersome.

We encourage you to keep your code blocks, printing statements, and final answers, as short as possible. In any case, there is a page limit of 6 pages per week, which encompasses the total length of this document which consists of the questions, your coding lines, and your answers. When your answers to questions of the respective week exceed this page limit, they will not be graded, resulting in zero points.

Each week consists of 1, 2, or 3 subquestions. The total amount of points you can earn per week is 20 points. 

# Week 1 

1.  Find the dataset “movies1.tsv” on Canvas. Describe your data set: How many observations does it have. How many variables are there? How many subjects? What consists of a subject? \textbf{[4 points]}

```{r}
movies <- read.table("movies1.tsv", header=TRUE)

head(movies)

ncol(movies)
nrow(movies)

```

**Your Answer**

We conclude that the data set has 19 variables and 505 subjects. Every subject consists of a unique movie. 

2. Which of the following types of variables are present in your data set? (i) nominal; (ii) ordinal; (iii); interval; (iv) ratio. If present, name one example of such a variable present in your data set. \textbf{[4 points]}

```{r}
#WRITE YOUR CODE HERE
str(movies)
```

**Your Answer:**

Nominal: present, for example genre and title 
Ordinal: not present
Inverval: present, for example release_year
Ratio: present, for example budget and revenue

3. A movie studio wants to know which types of movies give maximal profit. Perform the following steps to provide the movie studio with an analysis which corresponds to their request:

a. Create the variable profits as the revenue of a movie minus its budget. Report its mean, median, maximum, and minimum. \textbf{[2 points]}
b. Which movie has the highest profits in your data set and how much are these profits. Which movie has the lowest and how much are its profits? If multiple movies have the exact same highest or lowest profits, give only one example. \textbf{[2 points]}
c. Create a boxplot of the variable profits. Make sure it has an appropriate title, and appropriate titles and labels for the x- and y-axis. Give Q1, Q2, Q3, and Q4. What does this tell you about the nature of making money in the movies industry? \textbf{[2 points]}
d. Add a new variable to your data set the log of profits. When creating this variable, what happens to movies for which profits is zero or negative? What then happens when you calculate the mean of log of profits? \textbf{[2 points]}
e. For movies that have a profit of zero or less, replace log of profits with "NA". What is now the mean of log of profits? Create a boxplot for log of profits, again with an appropriate title, x- and y-axis labels. How does it compare to the boxplot you made under c.)? \textbf{[2 points]}
f. Create a scatterplot of with the runtime of movies on the x-axis and the average vote of movies on the y-axis. What do you conclude from the scatterplot? Are movies with a longer runtime considered worse or better by the audience, or does the audience not have a preference? Why do you think this is the case? \textbf{[2 points]}  

For each step, you should provide first all the code you used to answer the question and then formulate an answer using full sentences.

*Step a*

```{r}

library(tidyverse)

movies$profit = movies$revenue - movies$budget

movies %>%
  summarise(mean(profit),
            median(profit),
            min(profit),
            max(profit))

```

**Your Answer:**

The mean of the variable profit is 63.121.475 euros. 
The median of the variable profit is 1.900.000 euros.
the minimum of the variable profit is -90.000.000 euros
the maximum of the variable profit is 2.550.965.087 euros

*Step b*

```{r}

#WRITE YOUR CODE HERE
max_profit = max(movies$profit)
min_profit = min(movies$profit)

movies %>%
  filter(profit == max_profit) %>%
  select(title, profit)

movies %>%
  filter(profit == min_profit) %>%
  select(title, profit)

```

**Your Answer:**

The movie with the highest profit is Avatar, reporting a profit of 2.550.965.087.
The movie with the lowest profit/highest loss is Mighty Joe Young, reporting a profit of -90.000.000

*Step c*

```{r}

#WRITE YOUR CODE HERE
boxplot(movies$profit, 
        main="Variable Profit",
        ylab="Profit",
        xlab="Movies")

movies %>%
  summarise(Q1 = quantile(movies$profit, 0.25),
            Q2 = quantile(movies$profit, 0.50),
            Q3 = quantile(movies$profit, 0.75),
            Q4 = max(movies$profit))

boxplot(movies$profit,
        main='Boxplot of Variable Profit',
        ylab="Profit",
        xlab="Movies",
        outline = FALSE)
```

**Your Answer:**

We created two boxplots. The first code is for all variable data in the dataset. The resulting boxplot is very compact with many outliers. In the second code, which was written to create the boxplot, the outliers were removed. We did this using the line #outline = FALSE#. This provides a more specific view of the distribution of variable profit.

We calculated the quantiles based on all the data, including the outliers. These are the quantiles:
Q1 = 0
Q2 = 1.900.000
Q3 = 60.514.050
Q4 = 2.550.965.087

This data tells us that the movie industry is a high-risk, high-reward business, where the majority of films earn little, and profitability is driven by a small fraction of massive blockbusters.

*Step d*

```{r}
#WRITE YOUR CODE HERE

movies$log_profits = log(movies$profit)

movies %>%
  summarise(mean_profits = mean(movies$log_profits))

movies %>%
  summarise(mean_profits2 = mean(log_profits[is.finite(log_profits)], na.rm = TRUE))

```

**Your Answer:**

All films without profit are converted to -infinity, because the value of log(0) is not defined for any base of the logarithm
All films with a negative profit are converted to NaN, which means that the result of a mathematical calculation is not a valid number. This is because the logarithm is only defined for positive real numbers.

As a result, when calculating the average logarithm of profits, it returns NaN. To obtain an average, films with zero or negative profits should be excluded from the calculation, as their logarithm values are undefined. The average then only reflects films with positive profits. The only problem is that this distorts the result because loss-making or break-even films are not taken into account.

*Step e*

```{r}

#WRITE YOUR CODE HERE
movies$log_profits[movies$log_profits<=0]<- NA
movies$log_profits[is.nan(movies$log_profits)] <- NA

mean(movies$log_profits, na.rm = TRUE)

boxplot(movies$log_profits,
        main = "Boxplot of Variable Log(Profits)",
        xlab = "Movies",
        ylab = "Log of Profits")

```

**Your Answer:**
The log scale compresses extremely large profits and expands smaller ones, which places the values on a more manageable scale. Therefore the boxplot provides more information than in c. Additionally, all negative values have been removed from the data, so only positive values are visible in the boxplot. However, there are still outliers, which can be seen as the points below and above the boxplot.

*Step f*

```{r}

#WRITE YOUR CODE HERE
ggplot(movies, aes(x=runtime, y=vote_average))+
  geom_point()+
  geom_smooth(method="lm", se=T)

```

**Your Answer:**

The average lies around the 100 minutes, movies with a longer runtime are considered better. This suggests that viewers may perceive longer movies as more developed or higher quality.

# Week 2 
1 Is your dataset movies1.tsv the full population, or is it a sample of a larger population? If the latter, how would you describe the full population? \textbf{[4 points]}

```{r}
#WRITE YOUR CODE HERE

head(movies$index, n = 10)
nrow(movies)
```

**Your Answer:**

These numbers are the first ten index numbers of the responders of this data set. As you can see, many numbers are missing. This shows that this is an sample and not an entire population. There are 505 subjects (movies), while the index is showing there are many more. Furthermore, you can logically reason that more than 505 films have been made worldwide.   

2
a.  For which actor in your data set do you observe the most movies? \textbf{[2 points]} 
b.  What is the average revenue of the movie in which this actor plays and does the revenue lie above or below the revenue of an average movie according to your data set? \textbf{[2 points]}  
c.  How trustworthy do you consider your conclusion to answer 2b? Use the term "law of large numbers" in your explanation. \textbf{[2 points]} 

*step a*

```{r}
#WRITE YOUR CODE HERE
actor_counts <- sort(table(movies$first_actor), decreasing = TRUE)
head(actor_counts, 1)

```

**Your Answer:**

Bruce Willis is the actor who plays in the most movies. He plays in 7 movies.

*step b*

```{r}
#WRITE YOUR CODE HERE
movies %>% 
  filter(first_actor=="Bruce Willis") %>% 
  summarise(avg_revenue_Bruce=mean(revenue, na.rm=T))

movies %>%
  summarise(avg_revenue_data = mean(movies$revenue))
```

**Your Answer:**

The average revenue of the films of Bruce Willis is 116.280.090.
The average revenue of all the films is 94.815.482.
The average revenue of the films of Bruce Willis lies above the average revenue of all the films.

*step c*

**Your Answer:**
The conclusion in 2b is not very trustworthy, because it is based only on the subset of movies with Bruce Willis. According to the law of large numbers, the reliability of an average increases as the sample size grows. Since the number of Bruce Willis films in the dataset is much smaller (7) than the total number of films (505), his average revenue may not accurately reflect the true expectation and could be influenced by a few exceptionally high-grossing films.

3 For this question, you will assume that your data set is the full population. 
a. Recode profits such that it is expressed in millions. What is the variance of the variable profits (in millions) in your data set? \textbf{[2 points]}
b. Create a new data set, called movies_sample. Make sure that it is a random sample of your data set of 25 movies. What is the variance of profits in this random sample? How does it compare to the variance of profits in 2a? \textbf{[2 points]}
c. In a for loop, create 100 different samples of 25 movies, as in b, and estimate the variance within each sample. Save the variance of each sample in a vector called sample_vars. So the first position of the vector would have the variance of the first sample, the second position the variance of the second sample, etc. Print the start of this vector. \textbf{[2 points]}
d. Summarize and make a histogram of sample_vars. What is the mean, standard deviation and shape of its distribution? \textbf{[2 points]}
e. In your opinion, is a sample of 25 movies sufficient to get a reliable estimate of the population variance of profits, using the sample variance? Explain? \textbf{[2 points]}

*step a*

```{r}
#WRITE YOUR CODE HERE

movies$profit = movies$profit/1000000
variance = var(movies$profit)
```

**Your Answer:**

The variance of of the variable profits (in millions) is 30463,13

*step b*

```{r}
#WRITE YOUR CODE HERE

set.seed(123)

movies_sample <- movies[sample(nrow(movies), 25), ]
variance_sample = var(movies_sample$profit)

```

**Your Answer:**

The variance of profits in the sample of 25 movies is 5156 million, which is much lower than the variance of the full dataset. When we computed a sample multiple times, we saw a lot of changes in the variance. Sometimes there were no outliers which made the variance very low, but sometimes the variance was higher than the population variance. Normally we would expect the population variance to be lower, because it it a more precise variable. But in this case the sample chooses movies with less/no outliers, causing the variable to be lower.   

*step c*

```{r}
#WRITE YOUR CODE HERE

library(dplyr)

set.seed(123)

sample_vars <- c()
for (i in 1:100) {
  sample_data <- sample(movies$profit, size = 25, replace = TRUE)
  sample_vars[i] <- var(sample_data)
}

print(sample_vars)

```

**Your Answer:**

Above are the profit variances of 100 different samples.

*step d*

```{r}
#WRITE YOUR CODE HERE
dfsample_vars = as.data.frame(sample_vars)

ggplot(dfsample_vars, aes(x = sample_vars)) +
  geom_histogram(bins = 50) +
  labs(title = "Histogram of sample variances", x = "Sample variances", y = "Frequency")

dfsample_vars %>%
  summarise(mean_sample = mean(sample_vars),
            sd_sample = sd(sample_vars))

library(e1071)

skewness_sample = skewness(sample_vars, na.rm=T)
kurtosis_sample = kurtosis(sample_vars, na.rm=T)
print(skewness_sample)
print(kurtosis_sample)

```

**Your Answer:**

The mean of the sample variances is 22739,86.
The standard deviation of the sample variances is 36935,63.
The shape of the distribution is right-skewed, because of the positive skewness value. The kurtosis value is very high, because of the heavy outlier.  

*step e*

**Your Answer:**

A sample of 25 movies is relatively small for estimating the population variance of profits. The variance is very sensitive to extreme values, and as seen in the histogram, movie profits are highly skewed with large outliers. According to the law of large numbers, larger samples are needed for the sample variance to converge to the true population variance.

**Your answer here**

# Week 3 

For the next part of the assignment, assume that the movies in your data frame are a random sample of a larger population of movies. 

1
a. Create a new data set that only includes movies that are of the genre "Thriller". For these thriller movies, give a 99 percent confidence interval for the variable *runtime*. Interpret the result. \textbf{[2 points]}
b. Now, assume that the variance of *runtime* amongst thriller movies in your data is exactly the same as the variance of *runtime* in the population. Under this assumption, give a 99 percent confidence interval for the variable *runtime* among thriller movies. Interpret the result. Is you confidence interval wider or less wide than the one you found under question 1a? Why is that the case? \textbf{[2 points]}

*step a*

```{r}
#WRITE YOUR CODE HERE

thriller_movies <- subset(movies, grepl("Thriller", genre, ignore.case = FALSE))

t_result = t.test(thriller_movies$runtime, conf.level = 0.99)
conf_interval = t_result$conf.int
print(conf_interval)
```

**Your Answer:**

We are 99% confident that the true mean runtime of all thriller movies in the population falls between 99.94 and 111.01 minutes. 

*step b*

```{r}
#WRITE YOUR CODE HERE

mean_runtime = mean(thriller_movies$runtime)
sd_runtime = sd(thriller_movies$runtime)
n = length(thriller_movies$runtime)

sd_population = sd_runtime

alpha <- 0.01
z = qnorm(1-alpha/2)
error_margin = z*(sd_population/sqrt(n))
LOW = mean_runtime - error_margin
UP = mean_runtime + error_margin

print(c(LOW, UP))
```

**Your Answer:**

We are 99% confident that the true mean runtime of thriller movies in the entire population falls between 100.11 and 110.85 minutes. 

2
a. Using an appropriate five-step procedure, set up a test for the null hypothesis that the variance of runtime equals $500$. Clearly state your null hypothesis, alternative hypothesis your test statistic, your critical value, and your conclusion. \textbf{[2 points]}
b. For the validity of your test in 2a, what assumption about the distribution of revenue needs to hold? Make an appropriate plot to test this assumption. What do you conclude? \textbf{[2 points]}

*step a*

```{r}
#WRITE YOUR CODE HERE
s2 = var(movies$runtime, na.rm = TRUE)
n = sum(!is.na(movies$runtime))

# Hypothesized variance
sigma2 <- 500

# Test statistic
test_statistic <- (n - 1) * s2 / sigma2

# Print test statistic
cat("test statistic:", round(test_statistic, 2), "\n")

#critical value
alpha2 <- 0.05
lower <- qchisq(alpha / 2, df = n - 1)
upper <- qchisq(1 - alpha / 2, df = n - 1)

#print
cat("Critical values:\n")
cat("Lower:", round(lower, 2), "\n")
cat("Upper:", round(upper, 2), "\n")


#compare test statistic with the critical
if (test_statistic < lower || test_statistic > upper) {
  cat("Reject the null hypothesis.\n")
} else {
  cat("Do not reject the null hypothesis.\n")
}

```

**Your Answer:**

The null hypothesis (H0) is equal to 500. The alternative hypothesis (H1) is NOT equal to 500. 
We computed the test statistic and the critical values.
Our conclusion is that we do not reject the null hypothesis.

*step b*

```{r}
#WRITE YOUR CODE HERE
ggplot(movies, aes(x = runtime))+
  geom_histogram()+
  labs(title = "Histogram of runtime",
       y = "frequency")

ggplot(movies, aes(sample = runtime)) +
  stat_qq() +
  stat_qq_line(color = "purple") +
  labs(title = "Normal QQ plot",
       x = "Theoretical Quantiles",
       y = "Sample Quantilies") +
  theme_minimal()

```

**Your Answer:**

*I think there is a typo in question 2b, because for 2a we are doing hypothesis testing for the runtime. It would be weird to reason about assumptions of revenue, which has nothing to do with the runtime.

The assumption for the chi-square variance test is that the runtime variable is normally distributed. The histogram of runtime shows a concentration around 90–120 minutes, but the distribution is slightly right-skewed and has a few extreme outliers at both short and very long runtimes.
The Q-Q plot also shows clear deviations from the diagonal line, especially in the tails: very short and very long movies fall far from what would be expected under normality 
Together, these plots indicate that runtime is not perfectly normally distributed. Therefore the normality assumption does not hold, and the result of the variance test should be interpreted with caution.

3. There is an argument going on in the movie studio. *Bob* claims that they should make higher-quality movies, as this will bring in more profits. *Chantal* disagrees. She tells Bob that mediocre movies bring in the most profits. You are asked to advise on who is right.

a. Create a new variable called vote_average_rounded. Make sure this variable is the same as vote_average, but without any decimals (i.e., a 6.3 becomes a 6, a 8.7 an 8, etc.). Display a histogram of vote_average_rounded. \textbf{[2 points]}
b. Create a scatter plot with vote_average_rounded on the x axis and the mean of profits within each category of vote_average_rounded on the y-axis. Make sure it has an appropriate title, and appropriate titles and labels for the x- and y-axis. At which rating of movies are profits the highest? \textbf{[3 points]}
c. Recreate the scatter plot with year on the x axis and mean_profits on the y-axis, but now add bars around each point, indicating the 95\% confidence interval. \textbf{[3 points]}
d. Write an advice to settle the argument between Bob and Chantal. \textbf{[4 points]}

*step a*

```{r}
#WRITE YOUR CODE HERE
movies$vote_average_rounded <- floor(movies$vote_average)

ggplot(movies, aes(x = vote_average_rounded)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(breaks = seq(0,8, by = 1)) +
  labs(title = "Histogram of Rounded Vote Averages",
       x = "Vote Average",
       y = "Frequency") 
```

**Your Answer:**

With this code you create the new variable and a histogram.

*step b*

```{r}
#WRITE YOUR CODE HERE
profit_movies <- movies %>%
  group_by(vote_average_rounded) %>%
  summarise(profit_mean = mean(profit, na.rm = TRUE))


ggplot(profit_movies, aes(x = vote_average_rounded, y = profit_mean)) +
  geom_point(size = 3) +
  geom_line() +
  labs(
    title = "Average Profit by Rounded Vote Average",
    x = "Rounded Vote Average",
    y = "Average Profit (in millions)"
  ) 
```

**Your Answer:**

The profits are the highest by a rating of 8.

*step c*

```{r}
#WRITE YOUR CODE HERE

profit_by_year <- movies %>%
  group_by(release_year) %>%
  summarise(
    profit_mean = mean(profit, na.rm = TRUE),
    sd = sd(profit, na.rm = TRUE),
    n = n(),
    se = sd / sqrt(n),
    lower = profit_mean - 1.96 * se,
    upper = profit_mean + 1.96 * se
  )

ggplot(profit_by_year, aes(x = release_year, y = profit_mean)) +
  geom_point(size = 2, color = "darkblue") +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.3, color = "darkblue") +
  labs(
    title = "Average Profit per Year (95% Confidence Interval)",
    x = "Release Year",
    y = "Average Profit"
  ) +
  theme_minimal()
```

**Your Answer:**

Above you see the scatterplot created, with the 95% confident interval. We are not sure if it is a typo that we now have to compare the mean profit to the release year, because it is not relevant information for our dilemma. 

*step d*

**Your Answer:**

The plot shows that average profits rise with higher vote averages, peaking at ratings around 8. This supports Bob’s claim that higher-quality movies tend to be more profitable, rather than Chantal’s view that mediocre films bring in the most profit. The yearly profit plot shows high variation and wide confidence intervals, suggesting that other factors like market conditions and economic environment also matter. Still, overall the evidence favors Bob, primarily based on the scatterplot of question b.

